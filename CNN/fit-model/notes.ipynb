{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, Flatten, BatchNormalization, Dropout, MaxPool2D, Dense\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see ../pre-processing/clean_dataset/ for more info\n",
    "filepath = '/Users/chrisduckworth/projects/ML_portfolio/kin_mis_classification/CNN/pre-processing/clean_dataset_files/'\n",
    "\n",
    "X_train = np.load(filepath + 'X_train.npy')\n",
    "X_test = np.load(filepath + 'X_test.npy')\n",
    "X_val = np.load(filepath + 'X_val.npy')\n",
    "\n",
    "y_train = np.load(filepath + 'y_train.npy')\n",
    "y_test = np.load(filepath + 'y_test.npy')\n",
    "y_val = np.load(filepath + 'y_val.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping X data (i.e. adding channel) for CNN input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "X_val = X_val[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Updating labels to categorical\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "y_val = keras.utils.to_categorical(y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data generator objects to automatically augment training images to increase sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rotation_range = 45,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                               zoom_range = 0.2, # Randomly zoom image \n",
    "                               width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                               height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                               horizontal_flip = True)  # randomly flip images\n",
    "\n",
    "train_gen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_seq_CNN(input_shape):\n",
    "    '''\n",
    "    Building CNN model using keras sequential API.\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First convolutional block\n",
    "    model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = input_shape))\n",
    "    # Batch normalisation normalises output between layers \n",
    "    # (in a similar way to that data is normalised between 0 and 1 in the input layer).\n",
    "    # This enables higher learning rates / quicker convergence.\n",
    "    model.add(BatchNormalization())\n",
    "    # Pooling to avert small positional changes in features.\n",
    "    model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "    # Second convolutional block\n",
    "    model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "    # Third convolutional block\n",
    "    model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "    \n",
    "    # Fully connect layer and output.\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 128 , activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 3 , activation = 'softmax')) # 3 classes for output\n",
    "\n",
    "    # Compiling model with binary crossentropy. \n",
    "    model.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 187,971\n",
      "Trainable params: 187,651\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_seq_CNN((32, 32, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "199/199 [==============================] - 5s 26ms/step - loss: 0.5764 - accuracy: 0.6305 - val_loss: 0.9088 - val_accuracy: 0.2530\n",
      "Epoch 2/10\n",
      "199/199 [==============================] - 5s 26ms/step - loss: 0.4682 - accuracy: 0.6812 - val_loss: 2.0359 - val_accuracy: 0.2596\n",
      "Epoch 3/10\n",
      "199/199 [==============================] - 6s 28ms/step - loss: 0.4481 - accuracy: 0.6962 - val_loss: 0.6375 - val_accuracy: 0.5764\n",
      "Epoch 4/10\n",
      "199/199 [==============================] - 5s 27ms/step - loss: 0.4482 - accuracy: 0.6949 - val_loss: 0.6615 - val_accuracy: 0.5844\n",
      "Epoch 5/10\n",
      "199/199 [==============================] - 5s 27ms/step - loss: 0.4416 - accuracy: 0.7005 - val_loss: 0.6101 - val_accuracy: 0.6156\n",
      "Epoch 6/10\n",
      "199/199 [==============================] - 6s 28ms/step - loss: 0.4269 - accuracy: 0.7129 - val_loss: 0.4996 - val_accuracy: 0.6520\n",
      "Epoch 7/10\n",
      "199/199 [==============================] - 6s 29ms/step - loss: 0.4282 - accuracy: 0.7104 - val_loss: 0.5690 - val_accuracy: 0.5617\n",
      "Epoch 8/10\n",
      "199/199 [==============================] - 6s 30ms/step - loss: 0.4210 - accuracy: 0.7184 - val_loss: 0.5123 - val_accuracy: 0.6411\n",
      "Epoch 9/10\n",
      "199/199 [==============================] - 6s 31ms/step - loss: 0.4189 - accuracy: 0.7198 - val_loss: 0.4529 - val_accuracy: 0.6955\n",
      "Epoch 10/10\n",
      "199/199 [==============================] - 6s 32ms/step - loss: 0.4148 - accuracy: 0.7202 - val_loss: 0.5076 - val_accuracy: 0.6478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcd2fcf7150>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen.flow(X_train, y_train, batch_size=32),\n",
    "          validation_data=valid_gen.flow(X_val, y_val), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "- Unpack into functions.\n",
    "- Find optimal architecture using keras.tuner and number of layers.\n",
    "- Introduce different functional forms for learning rate (currently using adam which may already adapt).\n",
    "- Create learning rate plots and compare CNN vs FCN (for example).\n",
    "- Find package to visualise selected architecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
